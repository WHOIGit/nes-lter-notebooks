{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# your paths may vary\n",
    "notes_file = r'C:\\Users\\joefutrelle\\Desktop\\EN627_FLRTD492_logging_notes.txt'\n",
    "#start_stop_file = r'C:\\Users\\joefutrelle\\Desktop\\en627_flrtd_start_stop_times.csv'\n",
    "assert os.path.exists(notes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def lines_that_match(filename, regex):\n",
    "    with open(filename) as fin:\n",
    "        lines = fin.readlines()\n",
    "    return [l.rstrip() for l in lines if re.match(regex, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the logging notes to get start and stop times for FLRTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>filename</th>\n",
       "      <th>start_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-02 21:45:00+00:00</td>\n",
       "      <td>en627_20190202_214500</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-02 23:16:00+00:00</td>\n",
       "      <td>en627_20190202_214500</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-02 23:17:30+00:00</td>\n",
       "      <td>en627_20190202_231730</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-03 03:38:00+00:00</td>\n",
       "      <td>en627_20190202_231730</td>\n",
       "      <td>stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-03 03:40:00+00:00</td>\n",
       "      <td>en627_20190203_034000</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime               filename start_stop\n",
       "0 2019-02-02 21:45:00+00:00  en627_20190202_214500      start\n",
       "1 2019-02-02 23:16:00+00:00  en627_20190202_214500       stop\n",
       "2 2019-02-02 23:17:30+00:00  en627_20190202_231730      start\n",
       "3 2019-02-03 03:38:00+00:00  en627_20190202_231730       stop\n",
       "4 2019-02-03 03:40:00+00:00  en627_20190203_034000      start"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lines = lines_that_match(notes_file, r'.*recording')\n",
    "\n",
    "datetimes = []\n",
    "filenames = []\n",
    "sss = []\n",
    "\n",
    "for line in lines:\n",
    "    try:\n",
    "        datetime, _, filename, ss = re.match(r'(\\d{8} \\d\\d:\\d\\d(:\\d\\d)?) \\(\\w+\\) - (\\w+),? (.*) recording', line).groups()\n",
    "        datetimes.append(pd.Timestamp(datetime, tz='UTC'))\n",
    "        filenames.append(filename)\n",
    "        sss.append(ss)\n",
    "    except AttributeError:\n",
    "        print(line)\n",
    "        \n",
    "ss = pd.DataFrame({\n",
    "    'datetime': datetimes,\n",
    "    'filename': filenames,\n",
    "    'start_stop': sss\n",
    "})\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-02-02 21:45:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_times = ss[ss['start_stop'] == 'start']\n",
    "\n",
    "def start_time(filename):\n",
    "    rows = start_times[start_times['filename'] == filename]\n",
    "    if len(rows) == 1:\n",
    "        return rows.iloc[0]['datetime']\n",
    "\n",
    "start_time('en627_20190202_214500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the FLRTD log files to get the fluorometer data (var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from io import StringIO\n",
    "\n",
    "# Your paths may vary\n",
    "FLRTD_DIR = r'C:\\Users\\joefutrelle\\Desktop\\EN627_FLRTD492'\n",
    "OUT_DIR = r'C:\\Users\\joefutrelle\\Desktop\\en627_flrtd_cleaned'\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for flrtd_path in glob(os.path.join(FLRTD_DIR,'*.raw')):\n",
    "    filename_with_ext = os.path.basename(flrtd_path)\n",
    "    filename, _ = os.path.splitext(filename_with_ext)\n",
    "    lines = lines_that_match(flrtd_path, r'\\d\\d/\\d\\d/\\d\\d\\s+\\d\\d:\\d\\d:\\d\\d\\s+\\d+\\s\\d+\\s')\n",
    "    tsv = '\\n'.join(lines)\n",
    "    df = pd.read_csv(StringIO(tsv), delimiter='\\t')\n",
    "    df.columns = ['bad_date','bad_time','var1','var2','var3']\n",
    "    dfs[filename] = df\n",
    "\n",
    "def filename_start_time(filename):\n",
    "    y, m, d, H, M, S = re.match(r'\\w+_(\\d{4})(\\d\\d)(\\d\\d)_(\\d\\d)(\\d\\d)(\\d\\d).*', filename).groups()\n",
    "    return pd.Timestamp('{}/{}/{} {}:{}:{}'.format(y,m,d,H,M,S), tz='UTC')\n",
    "\n",
    "start_times = {}\n",
    "\n",
    "for filename, df in dfs.items():\n",
    "    ts = filename_start_time(filename)\n",
    "    start_times[filename] = ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate ~1hz timestamps for each FLRTD log starting from the start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticks(start_time, frequency, n):\n",
    "    return [start_time + pd.Timedelta(frequency) * i for i in range(n)]\n",
    "\n",
    "# 1.18hz = 847ms\n",
    "# rate appears to be 1.046hz = 965ms\n",
    "\n",
    "for filename, df in dfs.items():\n",
    "    ts = start_times[filename]\n",
    "    timestamps = ticks(ts, '965ms', len(df))\n",
    "    df['datetime'] = timestamps\n",
    "    out_path = os.path.join(OUT_DIR, '{}.csv'.format(filename))\n",
    "    try:\n",
    "        df.pop('bad_date')\n",
    "        df.pop('bad_time')\n",
    "    except KeyError:\n",
    "        pass\n",
    "    df.to_csv(out_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compare the end of those timestamps with the logged stop time to determine whether we have the right sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 00:00:02.730000')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns = []\n",
    "end_times = []\n",
    "\n",
    "for fn, df in dfs.items():\n",
    "    fns.append(fn)\n",
    "    end_times.append(pd.Timestamp(df['datetime'].values[-1], tz='UTC'))\n",
    "    \n",
    "merged = pd.DataFrame(dict(filename=fns,end_time=end_times)).merge(ss, on='filename')\n",
    "merged = merged[merged['start_stop'] == 'stop']\n",
    "merged.pop('start_stop')\n",
    "merged['time_difference'] = merged['datetime'] - merged['end_time']\n",
    "merged.columns = ['filename','estimated_end_time','logged_end_time','difference']\n",
    "merged.difference.median()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nes-lter-ims-dev]",
   "language": "python",
   "name": "conda-env-nes-lter-ims-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
